{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1phADYT6UZG6"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U wandb\n",
        "!pip install -q natsort tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHRy0mCJUY2p"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import axes_grid1\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from google.cloud import storage\n",
        "import tensorflow_datasets as tfds  \n",
        "\n",
        "from albumentations import (\n",
        "    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n",
        "    Rotate, Normalize\n",
        ")\n",
        "\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8DdHDqUUYzR"
      },
      "outputs": [],
      "source": [
        "MIXED_PRECISION = False\n",
        "XLA_ACCELERATE = False\n",
        "\n",
        "try:  # detect TPUs\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()  \n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    DEVICE = 'TPU'\n",
        "except ValueError:  # detect GPUs\n",
        "    strategy = tf.distribute.get_strategy() \n",
        "    DEVICE = 'GPU'\n",
        "    \n",
        "if DEVICE == \"GPU\":\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    print(\"Num GPUs Available: \", len(physical_devices))\n",
        "    try: \n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "        assert tf.config.experimental.get_memory_growth(physical_devices[0])\n",
        "    except: # Invalid device or cannot modify virtual devices once initialized.\n",
        "        pass \n",
        "    \n",
        "if MIXED_PRECISION:\n",
        "    dtype = 'mixed_bfloat16' if DEVICE == \"TPU\" else 'mixed_float16'\n",
        "    tf.keras.mixed_precision.set_global_policy(dtype)\n",
        "    dtype_model = tf.bfloat16\n",
        "    print('Mixed precision enabled')\n",
        "else:\n",
        "    dtype_model = tf.float32\n",
        "\n",
        "\n",
        "if XLA_ACCELERATE:\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "    print('Accelerated Linear Algebra enabled')\n",
        "    \n",
        "AUTO  = tf.data.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "\n",
        "print('REPLICAS           : ', REPLICAS)\n",
        "print('TensorFlow Version : ', tf.__version__)\n",
        "print('Eager Mode Status  : ', tf.executing_eagerly())\n",
        "print('TF Cuda Built Test : ', tf.test.is_built_with_cuda)\n",
        "print(\n",
        "    'TF Device Detected : ', \n",
        "    'Running on TPU' if DEVICE == \"TPU\" else tf.test.gpu_device_name()\n",
        ")\n",
        "\n",
        "try:\n",
        "    print('TF System Cuda V.  : ', tf.sysconfig.get_build_info()[\"cuda_version\"])\n",
        "    print('TF System CudNN V. : ', tf.sysconfig.get_build_info()[\"cudnn_version\"])\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7dmaBnBWj7B"
      },
      "outputs": [],
      "source": [
        "batch_size = 32 * REPLICAS\n",
        "image_shape = (256, 256)\n",
        "\n",
        "train_set_len = 28662 # for part 0 and for part 1: 655167\n",
        "valid_set_len = 7171\n",
        "train_step = -(-train_set_len // batch_size)\n",
        "val_step = valid_set_len // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f3fn666Vi6X"
      },
      "outputs": [],
      "source": [
        "GCS_DS_PATH_fer = \"gs://kds-39f11653dcf6e5ceb7705acf4ad46d05a1c259959db3a920906fe2f0\"\n",
        "train_shard_suffix = 'train_*-3.tfrec'\n",
        "test_shard_suffix = 'test_*-1.tfrec'\n",
        "train_set_path_fer = sorted(tf.io.gfile.glob(GCS_DS_PATH_fer + f'/train/{train_shard_suffix}'))\n",
        "test_set_path_fer = sorted(tf.io.gfile.glob(GCS_DS_PATH_fer + f'/test/{test_shard_suffix}'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjUs110VWJnY"
      },
      "outputs": [],
      "source": [
        "class Augmentation(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Augmentation, self).__init__()\n",
        "\n",
        "    @tf.function\n",
        "    def random_execute(self, prob: float) -> bool:\n",
        "\n",
        "        return tf.random.uniform([], minval=0, maxval=1) < prob\n",
        "\n",
        "\n",
        "class RandomToGrayscale(Augmentation):\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "        if self.random_execute(0.2):\n",
        "            x = tf.image.rgb_to_grayscale(x)\n",
        "            x = tf.tile(x, [1, 1, 3])\n",
        "        return x\n",
        "\n",
        "\n",
        "class RandomColorJitter(Augmentation):\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "        if self.random_execute(0.8):\n",
        "            x = tf.image.random_brightness(x, 0.8)\n",
        "            # x = tf.image.random_contrast(x, 0.4, 1.6)\n",
        "            # x = tf.image.random_saturation(x, 0.4, 1.6)\n",
        "            # x = tf.image.random_hue(x, 0.2)\n",
        "        return x\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "class RandomFlip(Augmentation):\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "\n",
        "        if self.random_execute(0.5):\n",
        "            x = tf.image.random_flip_left_right(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class RandomResizedCrop(Augmentation):\n",
        "\n",
        "    def __init__(self, image_size):\n",
        "        super(Augmentation, self).__init__()\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        rand_size = tf.random.uniform(\n",
        "            shape=[],\n",
        "            minval=int(0.8 * self.image_size),\n",
        "            maxval=1 * self.image_size,\n",
        "            dtype=tf.int32,\n",
        "        )\n",
        "\n",
        "        crop = tf.image.random_crop(x, (rand_size, rand_size, 3))\n",
        "        crop_resize = tf.image.resize(crop, (self.image_size, self.image_size))\n",
        "        return crop_resize\n",
        "\n",
        "\n",
        "class RandomSolarize(Augmentation):\n",
        "    @tf.function\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        if self.random_execute(0.2):\n",
        "            # flips abnormally low pixels to abnormally high pixels\n",
        "            x = tf.where(x < 10, x, 255 - x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RandomBlur(Augmentation):\n",
        "    @tf.function\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        if self.random_execute(0.2):\n",
        "            s = np.random.random()\n",
        "            return tfa.image.gaussian_filter2d(image=x, sigma=s)\n",
        "        return x\n",
        "\n",
        "\n",
        "class RandomAugmentor(keras.Model):\n",
        "    def __init__(self, image_size: int):\n",
        "        super(RandomAugmentor, self).__init__()\n",
        "        self.image_size = image_size\n",
        "        self.random_resized_crop = RandomResizedCrop(image_size)\n",
        "        self.random_flip = RandomFlip()\n",
        "        self.random_color_jitter = RandomColorJitter()\n",
        "        self.random_blur = RandomBlur()\n",
        "        self.random_to_grayscale = RandomToGrayscale()\n",
        "        self.random_solarize = RandomSolarize()\n",
        "        # self.random_rotage = RandomRotage()\n",
        "        # self.random_shear_x = RandomShear_x()\n",
        "        # self.random_cutout = RandomCutout()\n",
        "\n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        x = self.random_resized_crop(x)\n",
        "        x = self.random_flip(x)\n",
        "        x = self.random_color_jitter(x)\n",
        "        x = self.random_blur(x)\n",
        "        # x = tf.image.random_brightness(x, 0.2)\n",
        "        # x = tf.image.random_contrast(x, 0.5, 0.9)\n",
        "        # x = self.random_cutout(x)\n",
        "        x = self.random_rotage(x)\n",
        "        # x = tfa.image.random_cutout(x, 5)\n",
        "        # x = self.random_shear_x(x)\n",
        "        \n",
        "        # x = tf.image.ran\n",
        "        # x = self.random_to_grayscale(x)\n",
        "        # x = self.random_solarize(x)\n",
        "\n",
        "#         x = tf.clip_by_value(x, 0, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "bt_augmentor = RandomAugmentor(image_shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "333F7QGGMzpG"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import math\n",
        "IMAGE_SIZE = image_shape\n",
        "\n",
        "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
        "    # returns 3x3 transformmatrix which transforms indicies\n",
        "        \n",
        "    # CONVERT DEGREES TO RADIANS\n",
        "    rotation = math.pi * rotation / 180.\n",
        "    shear = math.pi * shear / 180.\n",
        "    \n",
        "    # ROTATION MATRIX\n",
        "    c1 = tf.math.cos(rotation)\n",
        "    s1 = tf.math.sin(rotation)\n",
        "    one = tf.constant([1],dtype='float32')\n",
        "    zero = tf.constant([0],dtype='float32')\n",
        "    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n",
        "        \n",
        "    # SHEAR MATRIX\n",
        "    c2 = tf.math.cos(shear)\n",
        "    s2 = tf.math.sin(shear)\n",
        "    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n",
        "\n",
        "    # ZOOM MATRIX\n",
        "    zoom_matrix = tf.reshape( tf.concat([one/height_zoom,zero,zero, zero,one/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n",
        "    \n",
        "    # SHIFT MATRIX\n",
        "    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n",
        "    \n",
        "    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n",
        "\n",
        "def transform(image):\n",
        "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
        "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
        "    DIM = IMAGE_SIZE[0]\n",
        "    XDIM = DIM%2 #fix for size 331\n",
        "    \n",
        "    rot = 15. * tf.random.normal([1],dtype='float32')\n",
        "    shr = 5. * tf.random.normal([1],dtype='float32') \n",
        "    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
        "    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')/10.\n",
        "    h_shift = 16. * tf.random.normal([1],dtype='float32') \n",
        "    w_shift = 16. * tf.random.normal([1],dtype='float32') \n",
        "\n",
        "    # GET TRANSFORMATION MATRIX\n",
        "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
        "\n",
        "    # LIST DESTINATION PIXEL INDICES\n",
        "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
        "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
        "    z = tf.ones([DIM*DIM],dtype='int32')\n",
        "    idx = tf.stack( [x,y,z] )\n",
        "    \n",
        "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
        "    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n",
        "    idx2 = K.cast(idx2,dtype='int32')\n",
        "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
        "    \n",
        "    # FIND ORIGIN PIXEL VALUES           \n",
        "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
        "    d = tf.gather_nd(image,tf.transpose(idx3))\n",
        "        \n",
        "    return tf.reshape(d,[DIM,DIM,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndx_U6-CWUm6"
      },
      "outputs": [],
      "source": [
        "WEIGHT = tf.constant([1.02660468, 9.40661861, 1.00104606, 0.56843877, 0.84912748,\n",
        "       1.29337298, 0.82603942])\n",
        "\n",
        "def tfrecords_loader_fer(files_path, shuffle=False, is_train=False):\n",
        "    datasets = tf.data.Dataset.from_tensor_slices(files_path)\n",
        "    datasets = datasets.shuffle(len(files_path)) if shuffle else datasets\n",
        "    datasets = datasets.flat_map(tf.data.TFRecordDataset)\n",
        "    \n",
        "    def deserialization_fn_fer(serialized_example):\n",
        "        features = tf.io.parse_single_example(\n",
        "            serialized_example,\n",
        "            features={\n",
        "                'image': tf.io.FixedLenFeature([], tf.string),\n",
        "                'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "            })\n",
        "\n",
        "        image = tf.image.decode_jpeg(features['image'], channels=3)\n",
        "        image = tf.image.resize(image, (265,265))\n",
        "        if is_train:\n",
        "            image = transform(image)\n",
        "        else:\n",
        "            image = tf.image.resize(image, image_shape)\n",
        "            \n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
        "        label = tf.cast(features['label'], tf.int64)  # [0-999]\n",
        "        \n",
        "        # print(features['label'])\n",
        "        sample_weight = tf.gather(WEIGHT, indices = label)\n",
        "\n",
        "        label = tf.one_hot(label, 7)\n",
        "\n",
        "        \n",
        "\n",
        "        return image, label, sample_weight\n",
        "    datasets = datasets.map(deserialization_fn_fer, num_parallel_calls=AUTO)\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f436azX5Wt9O"
      },
      "outputs": [],
      "source": [
        "train_datasets_fer = tfrecords_loader_fer(train_set_path_fer, is_train=True)\n",
        "test_datasets_fer = tfrecords_loader_fer(test_set_path_fer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datasets_fer.take(10)"
      ],
      "metadata": {
        "id": "98K9dHqKMX6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UE-E3KBtcuXH"
      },
      "outputs": [],
      "source": [
        "train_dataset_encode = train_datasets_fer.repeat().batch(batch_size).prefetch(AUTO)\n",
        "test_dataset_encode = test_datasets_fer.repeat().batch(batch_size).prefetch(AUTO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(test_dataset_encode))[1], next(iter(train_dataset_encode))[1]"
      ],
      "metadata": {
        "id": "6-2ijBiDMqqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcIwqh_30TSp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for i in range(10):\n",
        "iter_data = iter(train_datasets_fer)\n",
        "x = next(iter_data)[0].numpy()\n",
        "x = np.asarray(x * 127.5 + 127.5, dtype='uint8')\n",
        "print(x.min(), x.max())\n",
        "# print(x)\n",
        "plt.imshow(x)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 4  # 2x2, for the Transformer blocks.\n",
        "image_size = 256\n",
        "expansion_factor = 4  # expansion factor for the MobileNetV2 blocks.\n",
        "\n",
        "from tensorflow.keras import layers \n",
        "\n",
        "\n",
        "def conv_block(x, filters=16, kernel_size=3, strides=2):\n",
        "    x = layers.Conv2D(\n",
        "        filters, kernel_size, strides=strides, padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(momentum=0.1)(x)\n",
        "    x = tf.nn.swish(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "# Reference: https://git.io/JKgtC\n",
        "\n",
        "\n",
        "def inverted_residual_block(x, expanded_channels, output_channels, strides=1):\n",
        "    m = layers.Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False)(x)\n",
        "    m = layers.BatchNormalization(momentum=0.1)(m)\n",
        "    m = tf.nn.swish(m)\n",
        "\n",
        "    if strides == 2:\n",
        "        m = layers.ZeroPadding2D(padding=correct_pad(m, 3))(m)\n",
        "    m = layers.DepthwiseConv2D(\n",
        "        3, strides=strides, padding=\"same\" if strides == 1 else \"valid\", use_bias=False\n",
        "    )(m)\n",
        "    m = layers.BatchNormalization(momentum=0.1)(m)\n",
        "    m = tf.nn.swish(m)\n",
        "\n",
        "    m = layers.Conv2D(output_channels, 1, padding=\"same\", use_bias=False)(m)\n",
        "    m = layers.BatchNormalization(momentum=0.1)(m)\n",
        "\n",
        "    if tf.math.equal(x.shape[-1], output_channels) and strides == 1:\n",
        "        return layers.Add()([m, x])\n",
        "    return m\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.swish)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transformer_block(x, transformer_layers, projection_dim, num_heads=2):\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, x])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.1,)\n",
        "        # Skip connection 2.\n",
        "        x = layers.Add()([x3, x2])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def mobilevit_block(x, num_blocks, projection_dim, strides=1):\n",
        "    # Local projection with convolutions.\n",
        "    local_features = conv_block(x, filters=projection_dim, strides=strides)\n",
        "    se_features = SqueezeExcitation(projection_dim, projection_dim, 0.25)(local_features)\n",
        "    local_features = conv_block(\n",
        "        local_features, filters=projection_dim, kernel_size=1, strides=strides\n",
        "    )\n",
        "\n",
        "    # Unfold into patches and then pass through Transformers.\n",
        "    num_patches = int((local_features.shape[1] * local_features.shape[2]) / patch_size)\n",
        "    non_overlapping_patches = layers.Reshape((patch_size, num_patches, projection_dim))(\n",
        "        local_features\n",
        "    )\n",
        "    global_features = transformer_block(\n",
        "        non_overlapping_patches, num_blocks, projection_dim\n",
        "    )\n",
        "\n",
        "    # Fold into conv-like feature-maps.\n",
        "    folded_feature_map = layers.Reshape((*local_features.shape[1:-1], projection_dim))(\n",
        "        global_features\n",
        "    )\n",
        "\n",
        "    # Apply point-wise conv -> concatenate with the input features.\n",
        "    folded_feature_map = conv_block(\n",
        "        folded_feature_map, filters=x.shape[-1], kernel_size=1, strides=strides\n",
        "    )\n",
        "    local_global_features = layers.Concatenate(axis=-1)([x, folded_feature_map, se_features])\n",
        "\n",
        "    # Fuse the local and global features using a convoluion layer.\n",
        "    local_global_features = conv_block(\n",
        "        local_global_features, filters=projection_dim, strides=strides\n",
        "    )\n",
        "\n",
        "    return local_global_features\n",
        "\n",
        "class SqueezeExcitation(tf.keras.layers.Layer):\n",
        "  \"\"\"Creates a squeeze and excitation layer.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               in_filters,\n",
        "               out_filters,\n",
        "               se_ratio,\n",
        "               **kwargs):\n",
        "\n",
        "    super(SqueezeExcitation, self).__init__(**kwargs)\n",
        "\n",
        "    self._in_filters = in_filters\n",
        "    self._out_filters = out_filters\n",
        "    self._se_ratio = se_ratio\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    num_reduced_filters = max(1, int(self._in_filters * self._se_ratio))\n",
        "    self._se_reduce = tf.keras.layers.Conv2D(\n",
        "        filters=num_reduced_filters,\n",
        "        kernel_size=1,\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        use_bias=True,\n",
        "        )\n",
        "\n",
        "    self._se_expand = tf.keras.layers.Conv2D(\n",
        "        filters=self._out_filters,\n",
        "        kernel_size=1,\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        use_bias=True,\n",
        "        )\n",
        "\n",
        "    super(SqueezeExcitation, self).build(input_shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'in_filters': self._in_filters,\n",
        "        'out_filters': self._out_filters,\n",
        "        'se_ratio': self._se_ratio,\n",
        "    }\n",
        "    base_config = super(SqueezeExcitation, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = tf.reduce_mean(inputs, [1, 2], keepdims=True)\n",
        "    x = tf.nn.swish(self._se_reduce(x))\n",
        "    x = tf.nn.sigmoid(self._se_expand(x))\n",
        "    return x * inputs\n",
        "\n",
        "def correct_pad(inputs, kernel_size):\n",
        "    img_dim = 2 if tf.keras.backend.image_data_format() == \"channels_first\" else 1\n",
        "    input_size = tf.keras.backend.int_shape(inputs)[img_dim : (img_dim + 2)]\n",
        "    if isinstance(kernel_size, int):\n",
        "        kernel_size = (kernel_size, kernel_size)\n",
        "    if input_size[0] is None:\n",
        "        adjust = (1, 1)\n",
        "    else:\n",
        "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
        "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
        "    return (\n",
        "        (correct[0] - adjust[0], correct[0]),\n",
        "        (correct[1] - adjust[1], correct[1]),\n",
        "    )\n",
        "    \n",
        "\n",
        "def create_mobilevit(num_classes=1000):\n",
        "    inputs = keras.Input((image_size, image_size, 3))\n",
        "\n",
        "    x = conv_block(inputs, filters=16)\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=16 * expansion_factor, output_channels=32\n",
        "    )\n",
        "\n",
        "    # Downsampling with MV2 block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=32 * expansion_factor, output_channels=48, strides=2\n",
        "    )\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=48 * expansion_factor, output_channels=48\n",
        "    )\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=48 * expansion_factor, output_channels=48\n",
        "    )\n",
        "\n",
        "    # First MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=48 * expansion_factor, output_channels=64, strides=2\n",
        "    )\n",
        "    # x = SqueezeExcitation(48, 48, 0.25)(x)\n",
        "    x = mobilevit_block(x, num_blocks=2, projection_dim=96)\n",
        "    \n",
        "\n",
        "    # Second MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=80 * expansion_factor, output_channels=80, strides=2\n",
        "    )\n",
        "    # x = SqueezeExcitation(64, 64, 0.25)(x)\n",
        "    x = mobilevit_block(x, num_blocks=4, projection_dim=120)\n",
        "    \n",
        "\n",
        "    # Third MV2 -> MobileViT block.\n",
        "    x = inverted_residual_block(\n",
        "        x, expanded_channels=96 * expansion_factor, output_channels=96, strides=2\n",
        "    )\n",
        "    # x = SqueezeExcitation(80, 80, 0.25)(x)\n",
        "    x = mobilevit_block(x, num_blocks=3, projection_dim=144)\n",
        "    x = conv_block(x, filters=384, kernel_size=1, strides=1)\n",
        "\n",
        "    # Classification head.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(num_classes,activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "c1PNXw7vR--q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBCfHlsqW51E"
      },
      "outputs": [],
      "source": [
        "def get_encoder():\n",
        "    mobile = create_mobilevit()\n",
        "\n",
        "    dir_work = \"gs://cuong_tpu/logs/mobilevit/\"\n",
        "    ckpt = tf.train.Checkpoint(model=mobile)\n",
        "    ckpt.restore(tf.train.latest_checkpoint(dir_work+'ckpts'))\n",
        "    # mobile = create_mobilevit(num_classes=1000)\n",
        "    last_layer = mobile.layers[-2].output\n",
        "\n",
        "    model = keras.Model(mobile.input, last_layer)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umtQpqEWYT1p"
      },
      "outputs": [],
      "source": [
        "def get_projection_head(dims=[1280, 1024*2, 1024*5, 1024*5]):\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(dims[0],)),\n",
        "            keras.layers.Dense(dims[1]),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "            keras.layers.Dense(dims[2]),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.ReLU(),\n",
        "            keras.layers.Dense(dims[3]),\n",
        "        ],\n",
        "        name=\"projection_head\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw638r6KYYiy"
      },
      "outputs": [],
      "source": [
        "def get_linear_probe(z_dim):\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            keras.layers.Input(shape=(z_dim,)), \n",
        "            keras.layers.Dense(7)],\n",
        "        name=\"linear_probe\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i-KBqXnYdvG"
      },
      "outputs": [],
      "source": [
        "class BarlowModel(keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = get_encoder()\n",
        "        # self.counter = Counter()\n",
        "        z_dim = 1280\n",
        "        self.projection_head = get_projection_head([z_dim, 1024*2, 1024*5, 1024*5])\n",
        "        self.linear_probe = get_linear_probe(z_dim)\n",
        "\n",
        "\n",
        "    def compile(self, main_optimizer, probe_optimizer, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "\n",
        "        self.main_optimizer = main_optimizer\n",
        "        self.probe_optimizer = probe_optimizer\n",
        "\n",
        "        self.main_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
        "        self.main_loss_tracker_2 = keras.metrics.Mean()\n",
        "        # self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n",
        "        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
        "        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy(name=\"p_acc\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.main_loss_tracker,\n",
        "            self.main_loss_tracker_2,\n",
        "            # self.probe_loss_tracker,\n",
        "            self.probe_accuracy,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        y_a, y_b = batch\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_a_1, z_b_1 = self.encoder(y_a, training=True), self.encoder(y_b, training=True)\n",
        "            z_a_2, z_b_2 = self.projection_head(z_a_1, training=True), self.projection_head(z_b_1, training=True)\n",
        "            \n",
        "            main_loss = compute_loss(z_a_2, z_b_2)\n",
        "\n",
        "        gradients = tape.gradient(main_loss, \n",
        "                self.encoder.trainable_weights + self.projection_head.trainable_weights)\n",
        "        \n",
        "        self.main_optimizer.apply_gradients(\n",
        "            zip(\n",
        "                gradients,\n",
        "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.main_loss_tracker.update_state(main_loss)\n",
        "        \n",
        "        self.main_loss_tracker_2.update_state(self.counter())\n",
        "\n",
        "        return {\"loss\": self.main_loss_tracker.result(), \"assa\":self.main_loss_tracker_2.result()}\n",
        "    \n",
        "    def test_step(self, batch):\n",
        "        imgs, labels = batch\n",
        "        with tf.GradientTape() as tape:\n",
        "            features = self.encoder(imgs, training=False)\n",
        "            class_logits = self.linear_probe(features, training=True)\n",
        "            probe_loss = self.probe_loss(labels, class_logits)\n",
        "        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n",
        "        self.probe_optimizer.apply_gradients(\n",
        "            zip(gradients, self.linear_probe.trainable_weights)\n",
        "        )\n",
        "        self.probe_accuracy.update_state(labels, class_logits)\n",
        "        \n",
        "        return {\"acc\": self.probe_accuracy.result()} \n",
        "    \n",
        "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "        print(\"CALL\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py9J1u_4Yk0K"
      },
      "outputs": [],
      "source": [
        "class MyModel(keras.Model):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.acc_metric = keras.metrics.CategoricalAccuracy(name=\"acc\")\n",
        "        self.pre_metric = tf.keras.metrics.Precision(name=\"pre\")\n",
        "        self.rec_metric = tf.keras.metrics.Recall(name=\"rec\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker, self.acc_metric, self.pre_metric, self.rec_metric]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y, sample_weight = data\n",
        "        print(y.shape)\n",
        "\n",
        "        # print(self.__dict__)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute the loss value\n",
        "            # (the loss function is configured in `compile()`)\n",
        "            loss = self.loss(y, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.acc_metric.update_state(y, y_pred)\n",
        "        self.pre_metric.update_state(y, y_pred)\n",
        "        self.rec_metric.update_state(y, y_pred)\n",
        "        \n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y, sample_weight = data\n",
        "\n",
        "        y_pred = self(x, training=False)  # Forward pass\n",
        "        loss = self.loss(y, y_pred, sample_weight=sample_weight)\n",
        "        \n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.acc_metric.update_state(y, y_pred)\n",
        "        self.pre_metric.update_state(y, y_pred)\n",
        "        self.rec_metric.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "# Contrastive pretraining\n",
        "with strategy.scope():\n",
        "    pretraining_model = BarlowModel()\n",
        "    \n",
        "    pretraining_model.build(input_shape = (256,256,3))\n",
        "\n",
        "    encoder_model = get_encoder()\n",
        "    \n",
        "    x = encoder_model.output\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    x = keras.layers.Dropout(0.2)(x)\n",
        "    # x = keras.layers.\n",
        "    out = keras.layers.Dense(7)(x)\n",
        "\n",
        "    model_finetuning = MyModel(encoder_model.input, out)\n",
        "\n",
        "    model_finetuning.compile(\n",
        "        loss=keras.losses.CategoricalCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE),\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "trainable_count = np.sum(\n",
        "    [K.count_params(w) for w in model_finetuning.trainable_weights]\n",
        ")\n",
        "non_trainable_count = np.sum(\n",
        "    [K.count_params(w) for w in model_finetuning.non_trainable_weights]\n",
        ")\n",
        "print('Total params: {:,}'.format(trainable_count + non_trainable_count))\n",
        "print('Trainable params: {:,}'.format(trainable_count))\n",
        "print('Non-trainable params: {:,}'.format(non_trainable_count))"
      ],
      "metadata": {
        "id": "YKrxsDZvzfaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf8NvnYwY5FQ"
      },
      "outputs": [],
      "source": [
        "cb_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"model.h5\", monitor= \"val_acc\",verbose = 0, save_freq=\"epoch\",\n",
        ")\n",
        "\n",
        "history = model_finetuning.fit(\n",
        "    train_dataset_encode, epochs=50,\n",
        "    steps_per_epoch=train_step,\n",
        "    validation_data=test_dataset_encode, \n",
        "    validation_steps=val_step,\n",
        "    # class_weight=class_weights, \n",
        "    callbacks=[cb_checkpoint],\n",
        ")\n",
        "model_finetuning.load_weights(\"/content/model.h5\")\n",
        "history = model_finetuning.evaluate(test_dataset_encode, batch_size=128, steps=val_step)\n",
        "print(f\"Acc: {history[1]}, F1: {2*(history[2]*history[3])/(history[2]+history[3])}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}